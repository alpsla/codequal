/**
 * Comprehensive Production Researcher Service
 * 
 * Generates all 400 configurations with AI-powered selection
 * 10 roles × 10 languages × 4 repository sizes = 400 configurations
 */

import axios from 'axios';
import { AuthenticatedUser } from '@codequal/core/types';
import { Logger, createLogger } from '@codequal/core/utils';
import { ModelVersionSync, ModelVersionInfo } from '@codequal/core';
import { VectorStorageService, EnhancedChunk } from '@codequal/database';
import { ProductionResearcherService, ResearchResult, ModelConfiguration } from './production-researcher-service';
import { Logger as WinstonLogger } from 'winston';

const logger = createLogger('ComprehensiveResearcherService');

// Configuration constants
export const SUPPORTED_LANGUAGES = [
  'javascript', 'typescript', 'python', 'java', 'rust',
  'go', 'csharp', 'ruby', 'php', 'swift'
] as const;

export const REPOSITORY_SIZES = [
  'small', 'medium', 'large', 'extra_large'
] as const;

export const AGENT_ROLES = [
  'deepwiki', 'researcher', 'security', 'architecture', 'performance',
  'code_quality', 'dependencies', 'documentation', 'testing', 'translator'
] as const;

// Language-specific scoring adjustments
const LANGUAGE_SCORING_ADJUSTMENTS: Record<string, Partial<Record<string, number>>> = {
  python: { quality: 1.1, cost: 0.9 },
  javascript: { speed: 1.1, quality: 1.0 },
  typescript: { speed: 1.1, quality: 1.0 },
  java: { quality: 0.95, cost: 1.1 },
  rust: { quality: 1.05, cost: 1.0 },
  go: { speed: 1.15, cost: 0.85 },
  csharp: { quality: 0.95, cost: 1.05 },
  ruby: { quality: 1.0, cost: 0.95 },
  php: { quality: 0.9, cost: 1.0 },
  swift: { quality: 1.0, cost: 1.0 }
};

// Repository size scoring adjustments
const SIZE_SCORING_ADJUSTMENTS: Record<string, Partial<Record<string, number>>> = {
  small: { speed: 1.2, cost: 0.8, quality: 0.95 },
  medium: { speed: 1.0, cost: 1.0, quality: 1.0 },
  large: { speed: 0.9, cost: 1.2, quality: 1.1 },
  extra_large: { speed: 0.8, cost: 1.3, quality: 1.15 }
};

export interface ComprehensiveModelConfiguration extends ModelConfiguration {
  language: string;
  repositorySize: string;
  contextKey: string;
  contextSpecificWeights: Record<string, number>;
}

export interface ComprehensiveResearchResult extends ResearchResult {
  breakdown: {
    roles: number;
    languages: number;
    sizes: number;
    totalConfigurations: number;
    successfulConfigurations: number;
  };
  modelUsageStats: Record<string, number>;
}

export class ComprehensiveResearcherService extends ProductionResearcherService {
  
  /**
   * Perform comprehensive research with all 400 configurations
   */
  async performComprehensiveResearch(
    user: AuthenticatedUser,
    trigger: 'scheduled' | 'manual' = 'manual'
  ): Promise<ComprehensiveResearchResult> {
    const operationId = `comprehensive_research_${Date.now()}_${Math.random().toString(36).substring(2, 7)}`;
    const isSystemUser = (user as any).isSystemUser === true;
    
    logger.info('Starting COMPREHENSIVE model research', {
      operationId,
      trigger,
      userId: user.id,
      isSystemUser,
      userEmail: isSystemUser ? 'system' : user.email,
      expectedConfigurations: AGENT_ROLES.length * SUPPORTED_LANGUAGES.length * REPOSITORY_SIZES.length
    });

    const startTime = Date.now();
    const configurations: ComprehensiveModelConfiguration[] = [];
    const modelUsageStats: Record<string, number> = {};
    let processedCount = 0;
    let successCount = 0;

    try {
      // Step 1: Fetch and evaluate models
      const models = await this.fetchLatestModels();
      logger.info(`Fetched ${models.length} models from OpenRouter`);

      const modelMetrics = await this.prepareModelMetrics(models);
      const evaluatedModels = await this.evaluateModels(modelMetrics);
      logger.info(`Evaluated ${evaluatedModels.length} models with dynamic scoring`);

      // Step 2: Generate configurations for ALL combinations
      const totalCombinations = AGENT_ROLES.length * SUPPORTED_LANGUAGES.length * REPOSITORY_SIZES.length;

      // Batch process to avoid overwhelming the API
      const batchSize = 10;
      const batches: Array<{ role: string; language: string; size: string }[]> = [];
      
      // Create batches
      for (const role of AGENT_ROLES) {
        for (const language of SUPPORTED_LANGUAGES) {
          for (const size of REPOSITORY_SIZES) {
            const batchIndex = Math.floor(batches.length / batchSize);
            if (!batches[batchIndex]) batches[batchIndex] = [];
            batches[batchIndex].push({ role, language, size });
          }
        }
      }

      // Process batches
      for (const [batchIndex, batch] of batches.entries()) {
        logger.info(`Processing batch ${batchIndex + 1}/${batches.length}`);
        
        const batchConfigs = await Promise.all(
          batch.map(async ({ role, language, size }) => {
            try {
              processedCount++;
              if (processedCount % 50 === 0) {
                logger.info(`Progress: ${processedCount}/${totalCombinations} configurations (${(processedCount/totalCombinations*100).toFixed(1)}%)`);
              }

              // Apply context-specific weights
              const contextWeights = this.calculateContextWeights(role, language, size);
              
              // Re-evaluate models with context weights
              const contextEvaluatedModels = evaluatedModels.map(model => ({
                ...model,
                contextScore: this.calculateContextScore(model, contextWeights)
              }));

              // Sort by context score
              contextEvaluatedModels.sort((a, b) => (b.contextScore || 0) - (a.contextScore || 0));

              // Use AI to select from top candidates
              const topCandidates = contextEvaluatedModels.slice(0, 15);
              const context = {
                role,
                language,
                repositorySize: size === 'extra_large' ? 'enterprise' : size as any,
                requirements: this.getContextRequirements(role, language, size)
              };

              const aiSelection = await this.selectWithAI(topCandidates, context, models);
              
              const config: ComprehensiveModelConfiguration = {
                role,
                language,
                repositorySize: size,
                contextKey: `${role}_${language}_${size}`,
                primary: aiSelection.primary,
                fallback: aiSelection.fallback,
                reasoning: aiSelection.reasoning,
                contextSpecificWeights: contextWeights,
                lastUpdated: new Date(),
                updateFrequency: 'quarterly'
              };

              // Track model usage
              const primaryKey = `${config.primary.provider}/${config.primary.model}`;
              modelUsageStats[primaryKey] = (modelUsageStats[primaryKey] || 0) + 1;
              
              successCount++;
              return config;
              
            } catch (error) {
              logger.error(`Failed to select models for ${role}/${language}/${size}`, { error });
              return null;
            }
          })
        );

        // Add successful configs
        configurations.push(...batchConfigs.filter(c => c !== null) as ComprehensiveModelConfiguration[]);
        
        // Small delay between batches to avoid rate limits
        if (batchIndex < batches.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 1000));
        }
      }

      // Step 3: Store configurations in Vector DB
      logger.info('Storing configurations in Vector DB...');
      await this.storeAllConfigurations(configurations, user);

      // Step 4: Create comprehensive result
      const duration = Date.now() - startTime;
      const result: ComprehensiveResearchResult = {
        operationId,
        timestamp: new Date(),
        configurationsUpdated: configurations.length,
        modelsEvaluated: models.length,
        selectedConfigurations: configurations,
        nextScheduledUpdate: this.calculateNextQuarterlyUpdate(),
        breakdown: {
          roles: AGENT_ROLES.length,
          languages: SUPPORTED_LANGUAGES.length,
          sizes: REPOSITORY_SIZES.length,
          totalConfigurations: totalCombinations,
          successfulConfigurations: successCount
        },
        modelUsageStats
      };

      await this.storeOperationResult(result, user);

      logger.info('COMPREHENSIVE research completed successfully', {
        operationId,
        configurationsUpdated: result.configurationsUpdated,
        expectedConfigurations: totalCombinations,
        successRate: `${(successCount / totalCombinations * 100).toFixed(1)}%`,
        duration: `${(duration / 1000).toFixed(1)} seconds`,
        nextUpdate: result.nextScheduledUpdate,
        trigger,
        isSystemUser
      });

      // Log summary statistics
      this.logComprehensiveSummary(result);

      return result;

    } catch (error) {
      logger.error('Comprehensive research failed', { error, operationId });
      throw error;
    }
  }

  /**
   * Calculate context-specific weights
   */
  private calculateContextWeights(role: string, language: string, size: string): Record<string, number> {
    // Get base weights for role
    const baseWeights = this.getRoleWeights(role);
    
    // Apply language and size adjustments
    const langAdjustments = LANGUAGE_SCORING_ADJUSTMENTS[language] || {};
    const sizeAdjustments = SIZE_SCORING_ADJUSTMENTS[size] || {};
    
    const adjusted: Record<string, number> = {};
    
    // Apply multiplicative adjustments
    for (const [key, baseValue] of Object.entries(baseWeights)) {
      const langFactor = langAdjustments[key] || 1.0;
      const sizeFactor = sizeAdjustments[key] || 1.0;
      adjusted[key] = baseValue * langFactor * sizeFactor;
    }
    
    // Normalize weights to sum to 1.0
    const sum = Object.values(adjusted).reduce((a, b) => a + b, 0);
    for (const key in adjusted) {
      adjusted[key] = adjusted[key] / sum;
    }
    
    // Ensure all required weights are present
    return {
      quality: adjusted.quality || 0.4,
      speed: adjusted.speed || 0.3,
      cost: adjusted.cost || 0.3,
      freshness: adjusted.freshness || 0.0,
      contextWindow: adjusted.contextWindow || 0.0
    };
  }

  /**
   * Calculate context-specific score for a model
   */
  private calculateContextScore(model: any, weights: Record<string, number>): number {
    return (model.scores?.quality || 0) * weights.quality +
           (model.scores?.speed || 0) * weights.speed +
           (model.scores?.cost || 0) * weights.cost +
           (model.scores?.freshness || 0) * weights.freshness +
           (model.scores?.contextWindow || 0) * weights.contextWindow;
  }

  /**
   * Get context-specific requirements
   */
  private getContextRequirements(role: string, language: string, size: string): string {
    const requirements: string[] = [];
    
    // Role-specific requirements
    if (role === 'security') {
      requirements.push('High accuracy for vulnerability detection');
    } else if (role === 'performance') {
      requirements.push('Fast response times for optimization analysis');
    } else if (role === 'documentation') {
      requirements.push('Strong natural language generation capabilities');
    } else if (role === 'deepwiki') {
      requirements.push('Comprehensive code understanding and analysis');
    }
    
    // Language-specific requirements
    if (language === 'python') {
      requirements.push('Python idioms and async/await patterns');
    } else if (language === 'rust') {
      requirements.push('Memory safety and ownership comprehension');
    } else if (language === 'javascript' || language === 'typescript') {
      requirements.push('Modern JS/TS features and framework knowledge');
    } else if (language === 'go') {
      requirements.push('Concurrency patterns and Go idioms');
    }
    
    // Size-specific requirements
    if (size === 'small') {
      requirements.push('Quick analysis with minimal token usage');
    } else if (size === 'extra_large') {
      requirements.push('Efficient handling of large contexts and complex architectures');
    }
    
    return requirements.join('; ');
  }

  /**
   * Store all configurations in Vector DB
   */
  private async storeAllConfigurations(
    configurations: ComprehensiveModelConfiguration[],
    user: AuthenticatedUser
  ): Promise<void> {
    const RESEARCHER_CONFIG_REPO_ID = '00000000-0000-0000-0000-000000000001';
    let storedCount = 0;
    
    for (const config of configurations) {
      try {
        const chunk: EnhancedChunk = {
          content: JSON.stringify({
            ...config,
            modelSelectionVersion: '2.0', // Version for tracking updates
            comprehensiveResearch: true
          }),
          metadata: {
            type: 'model_configuration_v2',
            role: config.role,
            language: config.language,
            repositorySize: config.repositorySize,
            contextKey: config.contextKey,
            primaryModel: `${config.primary.provider}/${config.primary.model}`,
            fallbackModel: `${config.fallback.provider}/${config.fallback.model}`,
            lastUpdated: config.lastUpdated.toISOString(),
            version: '2.0'
          },
          embedding: [], // Will be generated by vector service
          filePath: `configurations/${config.contextKey}.json`
        };

        await this.vectorStorage.storeChunk(RESEARCHER_CONFIG_REPO_ID, chunk, user);
        storedCount++;
        
        if (storedCount % 50 === 0) {
          logger.info(`Stored ${storedCount}/${configurations.length} configurations`);
        }
      } catch (error) {
        logger.warn(`Failed to store configuration for ${config.contextKey}`, { error });
      }
    }
    
    logger.info(`Successfully stored ${storedCount}/${configurations.length} configurations`);
  }

  /**
   * Log comprehensive summary
   */
  private logComprehensiveSummary(result: ComprehensiveResearchResult): void {
    logger.info('=== COMPREHENSIVE RESEARCH SUMMARY ===');
    
    // Top models by usage
    const sortedModels = Object.entries(result.modelUsageStats)
      .sort((a, b) => b[1] - a[1])
      .slice(0, 10);
    
    logger.info('Top 10 most selected models:');
    sortedModels.forEach(([model, count], index) => {
      const percentage = (count / result.configurationsUpdated * 100).toFixed(1);
      logger.info(`  ${index + 1}. ${model}: ${count} configurations (${percentage}%)`);
    });
    
    // Breakdown by role
    const roleStats: Record<string, Set<string>> = {};
    result.selectedConfigurations.forEach(config => {
      if (!roleStats[config.role]) roleStats[config.role] = new Set();
      roleStats[config.role].add(`${config.primary.provider}/${config.primary.model}`);
    });
    
    logger.info('\nUnique models per role:');
    AGENT_ROLES.forEach(role => {
      const uniqueCount = roleStats[role]?.size || 0;
      logger.info(`  ${role}: ${uniqueCount} unique models`);
    });
    
    logger.info(`\nTotal configurations: ${result.breakdown.totalConfigurations}`);
    logger.info(`Successful configurations: ${result.breakdown.successfulConfigurations}`);
    logger.info(`Success rate: ${(result.breakdown.successfulConfigurations / result.breakdown.totalConfigurations * 100).toFixed(1)}%`);
  }

  /**
   * Get role weights
   */
  private getRoleWeights(role: string): Record<string, number> {
    const roleWeights: Record<string, Record<string, number>> = {
      deepwiki: { quality: 0.50, cost: 0.30, speed: 0.20 },
      researcher: { quality: 0.50, cost: 0.35, speed: 0.15 },
      security: { quality: 0.60, cost: 0.20, speed: 0.20 },
      architecture: { quality: 0.55, cost: 0.25, speed: 0.20 },
      performance: { quality: 0.35, cost: 0.25, speed: 0.40 },
      code_quality: { quality: 0.50, cost: 0.30, speed: 0.20 },
      dependencies: { quality: 0.30, cost: 0.40, speed: 0.30 },
      documentation: { quality: 0.45, cost: 0.35, speed: 0.20 },
      testing: { quality: 0.40, cost: 0.30, speed: 0.30 },
      translator: { quality: 0.55, cost: 0.30, speed: 0.15 }
    };
    
    return roleWeights[role] || { quality: 0.40, cost: 0.30, speed: 0.30 };
  }

  // Methods inherited from parent that need to be accessible
  protected async fetchLatestModels(): Promise<any[]> {
    return super['fetchLatestModels']();
  }

  protected async prepareModelMetrics(models: any[]): Promise<any[]> {
    return super['prepareModelMetrics'](models);
  }

  protected async evaluateModels(metrics: any[]): Promise<any[]> {
    return super['evaluateModels'](metrics);
  }

  protected async selectWithAI(candidates: any[], context: any, models: any[]): Promise<any> {
    return super['selectWithAI'](candidates, context, models);
  }

  protected calculateNextQuarterlyUpdate(): Date {
    return super['calculateNextQuarterlyUpdate']();
  }

  protected async storeOperationResult(result: any, user: AuthenticatedUser): Promise<void> {
    return super['storeOperationResult'](result, user);
  }
}