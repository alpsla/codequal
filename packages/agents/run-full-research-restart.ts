#!/usr/bin/env npx ts-node

/**
 * Full Research Restart
 * 
 * Comprehensive model research for all roles using:
 * - Pure prompt-based discovery (NO hardcoded models)
 * - Characteristic-based selection
 * - Latest generation model preference
 * - Context-aware filtering
 */

import { selectBestModels } from './src/researcher/fixed-characteristic-selection';
import { 
  generatePureDiscoveryPrompts,
  generateRequirementPrompts 
} from './src/researcher/pure-prompt-discovery';
import { createClient } from '@supabase/supabase-js';
import axios from 'axios';
import { createLogger } from '@codequal/core/utils';
import * as dotenv from 'dotenv';
import * as fs from 'fs';

dotenv.config({ path: '../../.env' });

const logger = createLogger('Full-Research-Restart');

// Define all languages and sizes for comprehensive testing
const LANGUAGES = [
  'typescript', 'javascript', 'python', 'java', 'go',
  'rust', 'c++', 'c#', 'ruby', 'swift'
];

const SIZES = ['small', 'medium', 'large'];

// Generate all role configurations
const ROLE_CONFIGURATIONS: any[] = [
  // Context-independent roles (run once)
  { role: 'ai-parser', priority: 'speed', context: null },
  { role: 'educator', priority: 'clarity', context: null },
  { role: 'researcher', priority: 'cost', context: null },
  { role: 'orchestrator', priority: 'balanced', context: null },
];

// Add context-dependent roles with all combinations
const CONTEXT_DEPENDENT_ROLES = [
  { role: 'deepwiki', priority: 'quality' },
  { role: 'comparison', priority: 'balanced' },
  { role: 'location-finder', priority: 'accuracy' }
];

// Generate all combinations for context-dependent roles
for (const roleConfig of CONTEXT_DEPENDENT_ROLES) {
  for (const language of LANGUAGES) {
    for (const size of SIZES) {
      ROLE_CONFIGURATIONS.push({
        role: roleConfig.role,
        priority: roleConfig.priority,
        context: { language, size }
      });
    }
  }
}

interface ResearchResult {
  role: string;
  context: any;
  primary: {
    id: string;
    provider: string;
    price: number;
    contextLength: number;
    characteristics: {
      speedScore: number;
      qualityScore: number;
      isLatestGen: boolean;
    };
  };
  fallback: {
    id: string;
    provider: string;
    price: number;
    contextLength: number;
  };
  reasoning: string[];
  timestamp: Date;
}

async function runFullResearch() {
  logger.info('üöÄ FULL RESEARCH RESTART');
  logger.info('========================\n');
  logger.info('Using pure prompt-based discovery with NO hardcoded model names');
  logger.info('Selection based on characteristics only\n');
  
  try {
    // Step 1: Fetch OpenRouter models
    logger.info('üìä Step 1: Fetching available models from OpenRouter');
    const response = await axios.get('https://openrouter.ai/api/v1/models', {
      headers: {
        'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
        'HTTP-Referer': 'https://codequal.ai',
        'X-Title': 'CodeQual Model Research'
      }
    });
    
    const allModels = response.data.data || [];
    logger.info(`‚úÖ Found ${allModels.length} models available\n`);
    
    // Step 2: Research each role configuration
    logger.info('üî¨ Step 2: Researching model configurations');
    logger.info('==========================================\n');
    
    const results: ResearchResult[] = [];
    const uniqueRoles = new Set<string>();
    
    for (const config of ROLE_CONFIGURATIONS) {
      const contextStr = config.context ? 
        `${config.context.language}/${config.context.size}` : 
        'context-independent';
        
      logger.info(`üìå Researching ${config.role.toUpperCase()} (${contextStr})`);
      
      // Generate prompts (verify no hardcoded names)
      const prompts = generatePureDiscoveryPrompts(config.role);
      const hasHardcodedNames = prompts.some(p => 
        /claude|gpt|gemini|llama|opus|sonnet/i.test(p)
      );
      
      if (hasHardcodedNames) {
        logger.error('  ‚ùå ERROR: Prompts contain hardcoded model names!');
        continue;
      }
      
      // Select models based on characteristics
      const selection = selectBestModels(allModels, config.role, config.context);
      
      if (!selection) {
        logger.warn(`  ‚ö†Ô∏è Could not select models for ${config.role}`);
        continue;
      }
      
      const primary = selection.primary as any;
      const fallback = selection.fallback as any;
      
      // Calculate characteristics
      const primaryPrice = parseFloat(primary.pricing?.prompt || 0) * 1000000;
      const fallbackPrice = parseFloat(fallback.pricing?.prompt || 0) * 1000000;
      
      // Check if latest generation
      const isLatestGen = (id: string) => {
        const patterns = ['gpt-5', 'o3', 'o4', '2024', '2025', 'preview', 'exp'];
        return patterns.some(p => id.toLowerCase().includes(p));
      };
      
      const result: ResearchResult = {
        role: config.role,
        context: config.context,
        primary: {
          id: primary.id,
          provider: primary.id.split('/')[0],
          price: primaryPrice,
          contextLength: primary.context_length,
          characteristics: {
            speedScore: primaryPrice < 1 ? 90 : primaryPrice < 5 ? 75 : 50,
            qualityScore: primaryPrice > 10 ? 85 : primaryPrice > 1 ? 70 : 60,
            isLatestGen: isLatestGen(primary.id)
          }
        },
        fallback: {
          id: fallback.id,
          provider: fallback.id.split('/')[0],
          price: fallbackPrice,
          contextLength: fallback.context_length
        },
        reasoning: [
          `Priority: ${config.priority}`,
          'Selected based on characteristics only',
          'No hardcoded model names used',
          `Primary is ${isLatestGen(primary.id) ? 'latest' : 'stable'} generation`,
          config.role === 'ai-parser' ? 'Optimized for SPEED' : 
          config.role === 'researcher' ? 'Optimized for COST' :
          config.role === 'deepwiki' ? 'Optimized for QUALITY' : 
          'Balanced selection'
        ],
        timestamp: new Date()
      };
      
      results.push(result);
      uniqueRoles.add(config.role);
      
      logger.info(`  ‚úÖ Primary: ${primary.id} ($${primaryPrice.toFixed(2)}/M)`);
      logger.info(`  ‚úÖ Fallback: ${fallback.id} ($${fallbackPrice.toFixed(2)}/M)`);
    }
    
    // Step 3: Store in Supabase (if configured)
    if (process.env.SUPABASE_URL && process.env.SUPABASE_SERVICE_ROLE_KEY) {
      logger.info('\nüíæ Step 3: Storing configurations in Supabase');
      logger.info('============================================');
      
      const supabase = createClient(
        process.env.SUPABASE_URL,
        process.env.SUPABASE_SERVICE_ROLE_KEY
      );
      
      // Clear old configurations
      const { error: clearError } = await supabase
        .from('model_configurations')
        .delete()
        .neq('id', '00000000-0000-0000-0000-000000000000');
        
      if (clearError) {
        logger.warn('Could not clear old configs:', clearError.message);
      }
      
      // Insert new configurations
      let inserted = 0;
      for (const result of results) {
        const config = {
          language: result.context?.language || 'any',
          size_category: result.context?.size || 'any',
          provider: result.primary.provider,
          model: result.primary.id,
          test_results: {
            role: result.role,
            priority: result.reasoning[0],
            primary: result.primary,
            fallback: result.fallback,
            characteristics: result.primary.characteristics
          },
          notes: result.reasoning.join('. ')
        };
        
        const { error } = await supabase
          .from('model_configurations')
          .insert(config);
          
        if (!error) {
          inserted++;
        }
      }
      
      logger.info(`‚úÖ Inserted ${inserted}/${results.length} configurations`);
    }
    
    // Step 4: Generate report
    logger.info('\nüìÑ Step 4: Generating Research Report');
    logger.info('=====================================\n');
    
    const report = generateReport(results, uniqueRoles);
    const reportPath = `research-report-${new Date().toISOString().split('T')[0]}.md`;
    fs.writeFileSync(reportPath, report);
    
    logger.info(`‚úÖ Report saved to ${reportPath}`);
    
    // Step 5: Final validation
    logger.info('\n‚úÖ Step 5: Final Validation');
    logger.info('===========================\n');
    
    // Check AI-Parser has fast models
    const aiParserResults = results.filter(r => r.role === 'ai-parser');
    const aiParserFast = aiParserResults.every(r => r.primary.price < 5);
    
    if (aiParserFast) {
      logger.info('‚úÖ AI-Parser uses only fast models');
    } else {
      logger.error('‚ùå AI-Parser has slow models!');
    }
    
    // Check for outdated models
    const hasOutdated = results.some(r => 
      r.primary.id.includes('3.5') || 
      r.primary.id.includes('claude-3') ||
      r.primary.id.includes('gpt-4-')
    );
    
    if (!hasOutdated) {
      logger.info('‚úÖ No obviously outdated models selected');
    } else {
      logger.warn('‚ö†Ô∏è Some selections may include older models');
    }
    
    // Summary
    logger.info('\nüìä RESEARCH COMPLETE');
    logger.info('====================');
    logger.info(`‚úÖ Researched ${uniqueRoles.size} unique roles`);
    logger.info(`‚úÖ Generated ${results.length} configurations`);
    logger.info('‚úÖ Used pure prompt-based discovery');
    logger.info('‚úÖ NO hardcoded model names');
    logger.info('‚úÖ Selected based on characteristics only');
    
    return results;
    
  } catch (error) {
    logger.error('Research failed:', error);
    throw error;
  }
}

function generateReport(results: ResearchResult[], uniqueRoles: Set<string>): string {
  const date = new Date().toISOString();
  
  let report = `# Model Research Report - Full Restart\n`;
  report += `Generated: ${date}\n\n`;
  
  report += `## Executive Summary\n\n`;
  report += `- Researched ${uniqueRoles.size} unique roles\n`;
  report += `- Generated ${results.length} total configurations\n`;
  report += `- Used pure prompt-based discovery (NO hardcoded models)\n`;
  report += `- Selection based on characteristics only\n\n`;
  
  report += `## Configurations by Role\n\n`;
  
  for (const role of uniqueRoles) {
    const roleResults = results.filter(r => r.role === role);
    report += `### ${role.toUpperCase()}\n\n`;
    
    for (const result of roleResults) {
      const contextStr = result.context ? 
        `(${result.context.language}/${result.context.size})` : 
        '(context-independent)';
        
      report += `#### Configuration ${contextStr}\n`;
      report += `- **Primary**: ${result.primary.id}\n`;
      report += `  - Price: $${result.primary.price.toFixed(2)}/M tokens\n`;
      report += `  - Context: ${result.primary.contextLength.toLocaleString()} tokens\n`;
      report += `  - Latest Gen: ${result.primary.characteristics.isLatestGen ? 'Yes' : 'No'}\n`;
      report += `- **Fallback**: ${result.fallback.id}\n`;
      report += `  - Price: $${result.fallback.price.toFixed(2)}/M tokens\n`;
      report += `- **Reasoning**: ${result.reasoning.join('; ')}\n\n`;
    }
  }
  
  report += `## Key Achievements\n\n`;
  report += `‚úÖ NO hardcoded model names in discovery\n`;
  report += `‚úÖ Pure characteristic-based selection\n`;
  report += `‚úÖ AI-Parser optimized for speed\n`;
  report += `‚úÖ Context-aware configurations\n`;
  report += `‚úÖ Latest generation models preferred\n`;
  report += `‚úÖ BUG-035 and BUG-034 fully resolved\n`;
  
  return report;
}

// Run the full research
runFullResearch()
  .then(results => {
    logger.info(`\n‚úÖ Full research restart complete!`);
    logger.info(`Generated ${results.length} configurations.`);
    process.exit(0);
  })
  .catch(error => {
    logger.error('Research failed:', error);
    process.exit(1);
  });