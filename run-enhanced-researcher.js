#!/usr/bin/env node

/**
 * Enhanced Researcher Runner
 * Generates all 800 model configurations
 */

// Load environment
require('dotenv').config();

// Set OpenRouter API key
// SECURITY: Never hardcode API keys. Use environment variables only
if (!process.env.OPENROUTER_API_KEY) {
  console.error('ERROR: OPENROUTER_API_KEY environment variable is required');
  process.exit(1);
}

console.log('=== ENHANCED RESEARCHER EXECUTION (800 CONFIGURATIONS) ===');
console.log(`Time: ${new Date().toISOString()}`);
console.log('Running as: SYSTEM USER (no authentication required)');
console.log('');

// Configuration constants
const AGENT_ROLES = [
  'deepwiki', 'researcher', 'security', 'architecture', 'performance',
  'code_quality', 'dependencies', 'documentation', 'testing', 'translator'
];

const SUPPORTED_LANGUAGES = [
  'javascript', 'typescript', 'python', 'java', 'rust',
  'go', 'csharp', 'ruby', 'php', 'swift'
];

const REPOSITORY_SIZES = ['small', 'medium', 'large', 'extra_large'];

// Language-specific adjustments
const LANGUAGE_ADJUSTMENTS = {
  python: { quality: 1.1, cost: 0.9 },
  javascript: { speed: 1.1 },
  typescript: { speed: 1.1 },
  java: { quality: 0.95, cost: 1.1 },
  rust: { quality: 1.05 },
  go: { speed: 1.15, cost: 0.85 },
  csharp: { quality: 0.95, cost: 1.05 },
  ruby: { cost: 0.95 },
  php: { quality: 0.9 },
  swift: {}
};

// Size-specific adjustments
const SIZE_ADJUSTMENTS = {
  small: { speed: 1.2, cost: 0.8, quality: 0.95 },
  medium: {},
  large: { speed: 0.9, cost: 1.2, quality: 1.1 },
  extra_large: { speed: 0.8, cost: 1.3, quality: 1.15 }
};

// Role weights
const ROLE_WEIGHTS = {
  deepwiki: { quality: 0.50, cost: 0.30, speed: 0.20 },
  researcher: { quality: 0.50, cost: 0.35, speed: 0.15 },
  security: { quality: 0.60, cost: 0.20, speed: 0.20 },
  architecture: { quality: 0.55, cost: 0.25, speed: 0.20 },
  performance: { quality: 0.35, cost: 0.25, speed: 0.40 },
  code_quality: { quality: 0.50, cost: 0.30, speed: 0.20 },
  dependencies: { quality: 0.30, cost: 0.40, speed: 0.30 },
  documentation: { quality: 0.45, cost: 0.35, speed: 0.20 },
  testing: { quality: 0.40, cost: 0.30, speed: 0.30 },
  translator: { quality: 0.55, cost: 0.30, speed: 0.15 }
};

// Fetch models from OpenRouter
const https = require('https');

async function fetchModels() {
  return new Promise((resolve, reject) => {
    const options = {
      hostname: 'openrouter.ai',
      port: 443,
      path: '/api/v1/models',
      method: 'GET',
      headers: {
        'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
        'Content-Type': 'application/json'
      }
    };

    console.log('[INFO] Fetching models from OpenRouter...');

    const req = https.request(options, (res) => {
      let data = '';
      res.on('data', (chunk) => { data += chunk; });
      res.on('end', () => {
        try {
          const response = JSON.parse(data);
          if (res.statusCode !== 200) {
            reject(new Error(`OpenRouter API error: ${JSON.stringify(response)}`));
            return;
          }
          resolve(response.data || []);
        } catch (error) {
          reject(error);
        }
      });
    });

    req.on('error', reject);
    req.end();
  });
}

// Calculate context-specific score
function calculateContextScore(model, role, language, size) {
  const baseWeights = ROLE_WEIGHTS[role] || { quality: 0.40, cost: 0.30, speed: 0.30 };
  const langAdj = LANGUAGE_ADJUSTMENTS[language] || {};
  const sizeAdj = SIZE_ADJUSTMENTS[size] || {};
  
  // Apply adjustments
  const weights = {};
  for (const [key, value] of Object.entries(baseWeights)) {
    const langFactor = langAdj[key] || 1.0;
    const sizeFactor = sizeAdj[key] || 1.0;
    weights[key] = value * langFactor * sizeFactor;
  }
  
  // Normalize
  const sum = Object.values(weights).reduce((a, b) => a + b, 0);
  for (const key in weights) {
    weights[key] = weights[key] / sum;
  }
  
  // Calculate score (simplified)
  const cost = parseFloat(model.pricing?.prompt || 0) + parseFloat(model.pricing?.completion || 0);
  const costScore = cost === 0 ? 1 : Math.min(1, 0.001 / cost);
  const contextScore = Math.min(1, model.context_length / 100000);
  const qualityScore = model.id.includes('gemini-2.5') ? 0.9 : 
                      model.id.includes('gpt-4') ? 0.85 :
                      model.id.includes('claude') ? 0.85 :
                      model.id.includes('deepseek') ? 0.8 :
                      0.7;
  
  return weights.quality * qualityScore + 
         weights.cost * costScore + 
         weights.speed * contextScore;
}

// Main execution
async function runEnhancedResearch() {
  try {
    const models = await fetchModels();
    console.log(`[INFO] Fetched ${models.length} models from OpenRouter`);
    
    // Filter usable models
    const usableModels = models.filter(m => 
      !m.id.toLowerCase().includes('embed') &&
      !m.id.toLowerCase().includes('vision') &&
      m.pricing &&
      (parseFloat(m.pricing.prompt) > 0 || parseFloat(m.pricing.completion) > 0)
    );
    
    console.log(`[INFO] ${usableModels.length} usable models after filtering`);
    
    const configurations = [];
    const modelUsageStats = new Map();
    let processedCount = 0;
    const totalConfigs = AGENT_ROLES.length * SUPPORTED_LANGUAGES.length * REPOSITORY_SIZES.length;
    
    console.log(`[INFO] Generating ${totalConfigs} configurations...`);
    console.log('');
    
    // Generate all configurations
    for (const role of AGENT_ROLES) {
      for (const language of SUPPORTED_LANGUAGES) {
        for (const size of REPOSITORY_SIZES) {
          processedCount++;
          
          // Calculate scores for all models in this context
          const scoredModels = usableModels.map(model => ({
            ...model,
            contextScore: calculateContextScore(model, role, language, size)
          })).sort((a, b) => b.contextScore - a.contextScore);
          
          // Select primary and fallback
          const primary = scoredModels[0];
          const fallback = scoredModels.find(m => 
            m.id.split('/')[0] !== primary.id.split('/')[0] // Different provider
          ) || scoredModels[1];
          
          const config = {
            role,
            language,
            repositorySize: size,
            primary: primary.id,
            fallback: fallback.id,
            primaryScore: primary.contextScore.toFixed(3),
            fallbackScore: fallback.contextScore.toFixed(3)
          };
          
          configurations.push(config);
          
          // Track usage
          modelUsageStats.set(primary.id, (modelUsageStats.get(primary.id) || 0) + 1);
          
          // Progress update
          if (processedCount % 100 === 0) {
            console.log(`[PROGRESS] ${processedCount}/${totalConfigs} configurations (${(processedCount/totalConfigs*100).toFixed(1)}%)`);
          }
        }
      }
    }
    
    console.log('');
    console.log('âœ… Enhanced research completed successfully!');
    console.log(`Total configurations generated: ${configurations.length}`);
    console.log('');
    
    // Show statistics
    console.log('=== MODEL USAGE STATISTICS ===');
    const sortedStats = Array.from(modelUsageStats.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 10);
    
    console.log('Top 10 most selected models:');
    sortedStats.forEach(([model, count], index) => {
      const percentage = (count / configurations.length * 100).toFixed(1);
      console.log(`  ${index + 1}. ${model}: ${count} times (${percentage}%)`);
    });
    
    // Show sample configurations
    console.log('\n=== SAMPLE CONFIGURATIONS ===');
    console.log('First 5 configurations:');
    configurations.slice(0, 5).forEach((config, index) => {
      console.log(`  ${index + 1}. ${config.role}/${config.language}/${config.repositorySize}:`);
      console.log(`     Primary: ${config.primary} (score: ${config.primaryScore})`);
      console.log(`     Fallback: ${config.fallback} (score: ${config.fallbackScore})`);
    });
    
    // Show researcher's configurations
    const researcherConfigs = configurations.filter(c => c.role === 'researcher');
    const uniqueResearcherModels = new Set(researcherConfigs.map(c => c.primary));
    
    console.log('\nðŸ”„ RESEARCHER SELF-UPDATE:');
    console.log(`  Total researcher configurations: ${researcherConfigs.length}`);
    console.log(`  Unique models selected: ${uniqueResearcherModels.size}`);
    console.log(`  Models: ${Array.from(uniqueResearcherModels).slice(0, 3).join(', ')}...`);
    
    // Cost estimation
    const avgTokensPerSelection = 1000;
    const selectionsNeeded = configurations.length; // Would use AI for each in production
    const cheapestModel = usableModels.sort((a, b) => 
      parseFloat(a.pricing.prompt) - parseFloat(b.pricing.prompt)
    )[0];
    
    const estimatedCost = selectionsNeeded * avgTokensPerSelection * parseFloat(cheapestModel.pricing.prompt) / 1000000;
    
    console.log('\nðŸ’° COST ESTIMATION:');
    console.log(`  If using AI for each selection (${cheapestModel.id}):`);
    console.log(`  ${selectionsNeeded} selections Ã— ${avgTokensPerSelection} tokens Ã— $${cheapestModel.pricing.prompt}/M`);
    console.log(`  Estimated total cost: $${estimatedCost.toFixed(4)}`);
    
    console.log('\nâœ… All 800 configurations generated successfully!');
    console.log(`Next scheduled run: ${getNextQuarterlyRun()}`);
    
  } catch (error) {
    console.error('[ERROR]', error);
  }
}

function getNextQuarterlyRun() {
  const now = new Date();
  const quarter = Math.floor(now.getMonth() / 3);
  const nextQuarter = (quarter + 1) % 4;
  const year = nextQuarter === 0 ? now.getFullYear() + 1 : now.getFullYear();
  return new Date(Date.UTC(year, nextQuarter * 3, 1, 5, 0, 0, 0)).toISOString();
}

// Run the enhanced research
runEnhancedResearch();